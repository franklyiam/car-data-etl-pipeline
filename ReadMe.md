# Car Data ETL Pipeline

A lightweight Python ETL pipeline that extracts car data from CSV, JSON, and XML files, transforms it for consistency, and loads it into a unified CSV output with logging support.

## ğŸš— Project Overview

This project implements a basic ETL (Extract, Transform, Load) pipeline using Python. It reads car data from different file formats (CSV, JSON, XML), standardizes the data (e.g., formatting, rounding, capitalization), and writes the cleaned dataset to a target CSV file. All actions are logged with timestamps for traceability.

## ğŸ“‚ Directory Structure

```
.
â”œâ”€â”€ etl_pipeline.py
â”œâ”€â”€ log_file.txt
â”œâ”€â”€ transformed_car_data.csv
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cars.csv
â”‚   â”œâ”€â”€ cars.json
â”‚   â””â”€â”€ cars.xml
```

> ğŸ“Œ Note: Ensure your data files are placed in the same directory as `etl_pipeline.py` or adjust the script as needed.

## ğŸ›  Requirements

- Python 3.6 or higher
- pandas

Install required packages:

```bash
pip install pandas
```

## ğŸš€ How to Run

1. Clone the repository and navigate into it:

```bash
git clone https://github.com/your-username/car-data-etl-pipeline.git
cd car-data-etl-pipeline
```

2. Add your CSV, JSON, and XML files into the project directory.

3. Run the ETL pipeline:

```bash
python etl_pipeline.py
```

4. Output:
   - Cleaned data is saved to `transformed_car_data.csv`
   - A log of the ETL steps is written to `log_file.txt`

## ğŸ§ª Sample Log Output

```
2025-Apr-29-13:01:02,ETL Job Started
2025-Apr-29-13:01:02,Extract phase Started
2025-Apr-29-13:01:03,Extract phase Ended
2025-Apr-29-13:01:03,Transform phase Started
2025-Apr-29-13:01:03,Transform phase Ended
2025-Apr-29-13:01:04,Load phase Started
2025-Apr-29-13:01:04,Load phase Ended
2025-Apr-29-13:01:04,ETL Job Ended
```

## âœï¸ Author

Developed by [Your Name]

## ğŸ“„ License

This project is licensed under the MIT License. See the `LICENSE` file for details.